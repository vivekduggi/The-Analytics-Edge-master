               #################  Election Forecasting  ################
               
```{r}
##### Importing dataset

polling = read.csv("PollingData.csv")
str(polling)
summary(polling)
```
```{r}
##### Breakdown of polling dataset's year variable

table(polling$Year) 

##### Note: In 2012 only 45 states out of 50 have the data, as the pollsters 
##### were sure about the missing 5 states that they didn't perform any polls
##### in the month leading up to the 2012 election.
##### So we'll predict only for 45 states.


```

```{r}
##### Taking care of missing data
##### Performing Multiple Imputation

library("mice")
simple = polling[c("Rasmussen", "SurveyUSA", "PropR","DiffCount")]
summary(simple)

##### Setting up seed value

set.seed(144)
imputed = complete(mice(simple))

##### Now we have our completed data.
##### We can copy their values in our original dataset
##### in summary of our data we will find that
##### there are no missing values now

polling$Rasmussen = imputed$Rasmussen
polling$SurveyUSA = imputed$SurveyUSA

summary(polling)
```

```{r}                      
                           #########################################################
                           ##################    Buliding Models    ################
                           #########################################################


##### Splitting our dataset

train = subset(polling, Year == 2004 | Year == 2008)
test = subset(polling, Year == 2012)
table(train$Republican)

##### Note: We see that in our training dataset 47 states are won by Democrates
##### and 53 by Republicans, and our baseline model predicts the most frequent
##### outcome, so our Baseline model's accuracy is 53%, which is very low,
##### and it is not credible.

##### Now we will choose a smart baseline model against which
##### we can compare our logistic regression model
 



                           #######  Smart Baseline Model  ########




##### Sign() function return 1 if input is positive, 0 if input is 0 and -1 if input is negative
##### Lets's take a look at the breakdown of sign of traing set's Rasmussen variable 

table(sign(train$Rasmussen))

##### Comparing training set's outcome against the sign of polling data

table(train$Republican, sign(train$Rasmussen))

```
```{r}
                           ##########   Logistic Regression  Model   ##########


##### Computing correlation between our independent variables

cor(train[c("Rasmussen", "SurveyUSA", "PropR", "DiffCount", "Republican")])

##### Note: In our correlation table we see that most of the values are
##### correlated to each other and so combining them isn't going to much
##### to produce a working regression model.
##### So we'll use a single independent variable which is highly correlated
##### to the dependent variable, i.e., "PropR"

mod1 = glm(Republican ~ PropR , data = train, family = "binomial")
summary(mod1)
```

```{r}
##### Making predictions

pred1 = predict(mod1, type = "response")
table(train$Republican, pred1 >= 0.5) 
```

```{r}
##### Making new model

mod2 = glm(Republican ~ SurveyUSA + DiffCount, data = train, family = "binomial")
summary(mod2)
pred2 = predict(mod2, type = "response")
table(train$Republican, pred2 >= 0.5)

##### Note: Looking at the two models we find that "mod2" is slightly
##### better than "mod1", so we'll use this to make predictions on our test set.
```

```{r}
                    ######################################################
                    #######  Making predictions on our test set ##########
                    ######################################################



##### 1. Predictions of our smart baseline model
##### We'll see that our smart baseline model make only four mistakes, i.e,
##### 4 times it predicted that a Republican will win but A democrat won instead.

table(test$Republican, sign(test$Rasmussen))

##### 2. Predictions of our mod2
##### We'll see that our mod2 makes only one error, i.e., 
##### only once it predicted that a Republican will win, when
##### a democrat won. So our model mod2 has a very high accuracy.

testPrediction = predict(mod2, newdata = test, type = "response")
table(test$Republican, testPrediction >= 0.5)

##### Now we'll take a look at the prediction that we got wrong.

subset(test, testPrediction >= 0.5 & Republican == 0)

```

